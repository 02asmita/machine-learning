{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of Data\n",
    "\n",
    "We want to understand what are the important trends in Machine Learning at the moment. So we want to get a list of articles about Machine Learning that people are talking about. We can do that from many sources, but we decided to pick three sources to do that.\n",
    "\n",
    "1. [Reddit.com - Machine Learning](https://www.reddit.com/r/MachineLearning/) - Reddit is a user generated discussion forum where recent articles and topics on Maching Learning are discussed by the community.\n",
    "\n",
    "2. [Data Tau](http://www.datatau.com/)- Data Tau is the hacker news for machine learning. Users post articles about latest trends in data science and machine learning and can have discussion arount it.\n",
    "\n",
    "3. [Twitter #machinelearning](https://twitter.com/search?q=%23machinelearning&src=typd) - We can also look at Twitter with #machinelearning tags to find the latest articles and post about machine learning that are being discussed in the social media.\n",
    "\n",
    "\n",
    "## Working with Data Tau\n",
    "\n",
    "Let us start with Data Tau site and scrape the data to acquire it.\n",
    "\n",
    "![](img/datatau.png)\n",
    "\n",
    "We will want to scrape the title and date for each of the article in this page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'http://www.datatau.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the HTML Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us use request to get the url\n",
    "dataTau = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the page has been scraped - we should see Response 200\n",
    "dataTau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let us see the text content of the page\n",
    "# dataTau.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start the beautifulsoup library and create a soup!\n",
    "soup = BeautifulSoup(dataTau.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See the pretty form HTML - Not so pretty though!\n",
    "# print (soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the title in each page\n",
    "\n",
    "We have 30 articles on each page. Let us see if we can get the html tag and attribute to get this data\n",
    "\n",
    "Let us see which html tag we need the '`td .title`'\n",
    "\n",
    "![](img/title.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_class = soup.select('td .title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting double the number -> Let us see why by examining the first two elements in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td align=\"right\" class=\"title\" valign=\"top\">1.</td>,\n",
       " <td class=\"title\"><a href=\"https://www.youtube.com/watch?v=KeJINHjyzOU\">Deep Advances in Generative Modeling</a><span class=\"comhead\"> (youtube.com) </span></td>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_class[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha - We are getting both the number and the title name. We need to be even more specific and pick only the one with `<a>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_class = soup.select('td .title a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we get 31 and not 30 articles... Lets check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.youtube.com/watch?v=KeJINHjyzOU\">Deep Advances in Generative Modeling</a>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep Advances in Generative Modeling'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_class[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/x?fnid=zmYKlAHgNy\" rel=\"nofollow\">More</a>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_class[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... so the last link is the link to the \"More\" - which is the next page. That is good. We can use it to get the link to the next url to scrape\n",
    "\n",
    "**NOTE: Taking care of the edge cases**\n",
    "\n",
    "When we run this on multiple pages, we find that sometimes there are more than one `<a>` link in the title. To take of this we re-write the selection criterion to only pick the first `<a>` link in the title only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_class = soup.select('td .title > a:nth-of-type(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep Advances in Generative Modeling'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_class[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the date for each title\n",
    "\n",
    "To get the date for each title, we need html tag and class - '`td .subtext`'\n",
    "\n",
    "![](img/date.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_class = soup.select('.subtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"subtext\"><span id=\"score_11973\">6 points</span> by <a href=\"user?id=gwulfs\">gwulfs</a> 5 hours ago  | <a href=\"item?id=11973\">discuss</a></td>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_class[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6 points by gwulfs 5 hours ago  | discuss'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_class[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the Scraping Process\n",
    "\n",
    "We now write a function which starts with first page, gets all the title and date string and puts it in to a dataframe and then moves to the next page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "date     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us create an empty dataframe to store the data\n",
    "df = pd.DataFrame(columns=['title','date'])\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_from_tau(url):\n",
    "    print(url)\n",
    "    dataTau = requests.get(url)\n",
    "    soup = BeautifulSoup(dataTau.content,'html.parser')\n",
    "    title_class = soup.select('td .title > a:nth-of-type(1)')\n",
    "    date_class = soup.select('.subtext')\n",
    "    print(len(title_class),len(date_class))\n",
    "    for i in range(len(title_class)-1):\n",
    "        df.loc[df.shape[0]] = [title_class[i].get_text(),date_class[i].get_text()]\n",
    "    print('updated df with data')\n",
    "    return title_class[len(title_class) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.datatau.com\n",
      "31 30\n",
      "updated df with data\n",
      "http://www.datatau.com/x?fnid=MZdGRW3odn\n",
      "31 30\n",
      "updated df with data\n",
      "http://www.datatau.com/x?fnid=SuhXPcl1FI\n",
      "31 30\n",
      "updated df with data\n",
      "http://www.datatau.com/x?fnid=ek8XXt9Rac\n",
      "31 30\n",
      "updated df with data\n",
      "http://www.datatau.com/x?fnid=KdMQRvGXDC\n",
      "31 30\n",
      "updated df with data\n",
      "http://www.datatau.com/x?fnid=brd5WnrBqZ\n",
      "31 30\n",
      "updated df with data\n"
     ]
    }
   ],
   "source": [
    "url = base_url\n",
    "for i in range(0,6):\n",
    "    more_url = get_data_from_tau(url)\n",
    "    url = base_url+more_url['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Advances in Generative Modeling</td>\n",
       "      <td>6 points by gwulfs 5 hours ago  | discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Neural Network in 11 lines of Python</td>\n",
       "      <td>2 points by dekhtiar 5 hours ago  | discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python, Machine Learning, and Language Wars</td>\n",
       "      <td>3 points by pmigdal 7 hours ago  | discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Markov Chains Explained Visually</td>\n",
       "      <td>11 points by zeroviscosity 1 day ago  | 1 comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dplython: Dplyr for Python</td>\n",
       "      <td>10 points by thenaturalist 1 day ago  | 3 comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0         Deep Advances in Generative Modeling   \n",
       "1      A Neural Network in 11 lines of Python    \n",
       "2  Python, Machine Learning, and Language Wars   \n",
       "3             Markov Chains Explained Visually   \n",
       "4                   Dplython: Dplyr for Python   \n",
       "\n",
       "                                                date  \n",
       "0          6 points by gwulfs 5 hours ago  | discuss  \n",
       "1        2 points by dekhtiar 5 hours ago  | discuss  \n",
       "2         3 points by pmigdal 7 hours ago  | discuss  \n",
       "3  11 points by zeroviscosity 1 day ago  | 1 comment  \n",
       "4  10 points by thenaturalist 1 day ago  | 3 comm...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('data_tau.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
