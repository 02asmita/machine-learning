{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_tau_ta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>days</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Years of Open Source Machine Learning</td>\n",
       "      <td>7 points by tstonez 19 hours ago  | 1 comment</td>\n",
       "      <td>1</td>\n",
       "      <td>['10', 'years', 'open', 'source', 'machine', '...</td>\n",
       "      <td>10 Years of Open Source Machine Learn</td>\n",
       "      <td>10 Years of Open Source Machine Learning</td>\n",
       "      <td>[('10', 'CD'), ('Years', 'NNS'), ('of', 'IN'),...</td>\n",
       "      <td>['Open Source Machine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What machines can learn from Apple Watch: dete...</td>\n",
       "      <td>2 points by koukouhappy 7 hours ago  | discuss</td>\n",
       "      <td>1</td>\n",
       "      <td>['machines', 'learn', 'apple', 'watch', 'detec...</td>\n",
       "      <td>What machines can learn from Apple Watch: dete...</td>\n",
       "      <td>What machines can learn from Apple Watch: dete...</td>\n",
       "      <td>[('What', 'WP'), ('machines', 'NNS'), ('can', ...</td>\n",
       "      <td>['Apple Watch']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Deep Roots of Javascript Fatigue</td>\n",
       "      <td>3 points by nikkielizdemere 13 hours ago  | di...</td>\n",
       "      <td>1</td>\n",
       "      <td>['deep', 'roots', 'javascript', 'fatigue']</td>\n",
       "      <td>The Deep Roots of Javascript Fatigu</td>\n",
       "      <td>The Deep Roots of Javascript Fatigue</td>\n",
       "      <td>[('The', 'DT'), ('Deep', 'NNP'), ('Roots', 'NN...</td>\n",
       "      <td>['Deep Roots', 'Javascript Fatigue']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data science intro for math/phys background</td>\n",
       "      <td>9 points by pmigdal 1 day ago  | discuss</td>\n",
       "      <td>1</td>\n",
       "      <td>['data', 'science', 'intro', 'math', 'phys', '...</td>\n",
       "      <td>Data science intro for math/phys background</td>\n",
       "      <td>Data science intro for math/phys background</td>\n",
       "      <td>[('Data', 'NNP'), ('science', 'NN'), ('intro',...</td>\n",
       "      <td>['Data']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Pop-Up in Austin, TX</td>\n",
       "      <td>2 points by AnnaOnTheWeb 13 hours ago  | discuss</td>\n",
       "      <td>1</td>\n",
       "      <td>['data', 'science', 'pop', 'austin', 'tx']</td>\n",
       "      <td>Data Science Pop-Up in Austin, TX</td>\n",
       "      <td>Data Science Pop-Up in Austin, TX</td>\n",
       "      <td>[('Data', 'NNP'), ('Science', 'NNP'), ('Pop', ...</td>\n",
       "      <td>['Data Science Pop', 'Austin']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0           10 Years of Open Source Machine Learning   \n",
       "1  What machines can learn from Apple Watch: dete...   \n",
       "2               The Deep Roots of Javascript Fatigue   \n",
       "3        Data science intro for math/phys background   \n",
       "4                  Data Science Pop-Up in Austin, TX   \n",
       "\n",
       "                                                date  days  \\\n",
       "0      7 points by tstonez 19 hours ago  | 1 comment     1   \n",
       "1     2 points by koukouhappy 7 hours ago  | discuss     1   \n",
       "2  3 points by nikkielizdemere 13 hours ago  | di...     1   \n",
       "3           9 points by pmigdal 1 day ago  | discuss     1   \n",
       "4   2 points by AnnaOnTheWeb 13 hours ago  | discuss     1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['10', 'years', 'open', 'source', 'machine', '...   \n",
       "1  ['machines', 'learn', 'apple', 'watch', 'detec...   \n",
       "2         ['deep', 'roots', 'javascript', 'fatigue']   \n",
       "3  ['data', 'science', 'intro', 'math', 'phys', '...   \n",
       "4         ['data', 'science', 'pop', 'austin', 'tx']   \n",
       "\n",
       "                                                stem  \\\n",
       "0              10 Years of Open Source Machine Learn   \n",
       "1  What machines can learn from Apple Watch: dete...   \n",
       "2                The Deep Roots of Javascript Fatigu   \n",
       "3        Data science intro for math/phys background   \n",
       "4                  Data Science Pop-Up in Austin, TX   \n",
       "\n",
       "                                               lemma  \\\n",
       "0           10 Years of Open Source Machine Learning   \n",
       "1  What machines can learn from Apple Watch: dete...   \n",
       "2               The Deep Roots of Javascript Fatigue   \n",
       "3        Data science intro for math/phys background   \n",
       "4                  Data Science Pop-Up in Austin, TX   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [('10', 'CD'), ('Years', 'NNS'), ('of', 'IN'),...   \n",
       "1  [('What', 'WP'), ('machines', 'NNS'), ('can', ...   \n",
       "2  [('The', 'DT'), ('Deep', 'NNP'), ('Roots', 'NN...   \n",
       "3  [('Data', 'NNP'), ('science', 'NN'), ('intro',...   \n",
       "4  [('Data', 'NNP'), ('Science', 'NNP'), ('Pop', ...   \n",
       "\n",
       "                         named_entities  \n",
       "0               ['Open Source Machine']  \n",
       "1                       ['Apple Watch']  \n",
       "2  ['Deep Roots', 'Javascript Fatigue']  \n",
       "3                              ['Data']  \n",
       "4        ['Data Science Pop', 'Austin']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop.extend(('.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','/','-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens_list = df['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['10', 'years', 'open', 'source', 'machine', 'learning']\",\n",
       " \"['machines', 'learn', 'apple', 'watch', 'detecting', 'undiagnosed', 'heart', 'condition']\",\n",
       " \"['deep', 'roots', 'javascript', 'fatigue']\",\n",
       " \"['data', 'science', 'intro', 'math', 'phys', 'background']\",\n",
       " \"['data', 'science', 'pop', 'austin', 'tx']\",\n",
       " \"['data', 'science', 'tools', 'biggest', 'winners', 'losers']\",\n",
       " \"['analyzing', 'golden', 'state', 'warriors', 'passing', 'network', 'using', 'graphframes', 'spark']\",\n",
       " \"['making', 'transparent', 'variations', 'analytical', 'choices', 'affect', 'results']\",\n",
       " \"['neural', 'networks', 'demystified']\",\n",
       " \"['conversion', 'rate', 'changed', 'bayesian', 'timeseries', 'analysis', 'python']\",\n",
       " \"['descriptive', 'statistics', 'sql']\",\n",
       " \"['xgboost4j', 'portable', 'distributed', 'xgboost', 'spark', 'flink', 'dataflow']\",\n",
       " \"['introduction', 'scikit', 'flow', 'simplified', 'interface', 'tensorflow']\",\n",
       " \"['personality', 'space', 'cartoon', 'characters']\",\n",
       " \"['machine', 'learning', 'depth', 'non', 'technical', 'guide', '???', 'part', '4']\",\n",
       " \"['learn', 'machine', 'learning']\",\n",
       " \"['make', 'data', 'tau', 'work']\",\n",
       " \"['7', 'big', 'data', 'technologies', 'use', 'data', 'engineers', 'know']\",\n",
       " \"['data', 'science', 'slack', 'channel', 'click', 'invite']\",\n",
       " \"['minecraft', 'run', 'artificial', 'intelligence', 'experiments']\",\n",
       " \"['deep', 'q', 'learning', 'space', 'invaders']\",\n",
       " \"['megaman', 'manifold', 'learning', 'millions', 'points']\",\n",
       " \"['computing', 'classification', 'evaluation', 'metrics', 'r']\",\n",
       " \"['billion', 'taxi', 'rides', 'amazon', 'emr', 'running', 'presto']\",\n",
       " \"['scala', 'better', 'choice', 'python', 'apache', 'spark']\",\n",
       " \"['julia', 'fast', 'language', 'numerical', 'computing']\",\n",
       " \"['intellexer', 'natural', 'language', 'processing', 'text', 'mining', 'rest', 'api']\",\n",
       " \"['shiny', 'app', 'running', 'tensorflow', 'demo']\",\n",
       " \"['playing', 'moneyball', 'ea', 'fifa', '16']\",\n",
       " \"['file', 'details', 'owners', 'gitnoc', 'git', 'pandas']\",\n",
       " \"['ballr', 'interactive', 'nba', 'shot', 'charts', 'r', 'shiny']\",\n",
       " \"['bayesian', 'estimation', 'g', 'train', 'wait', 'times']\",\n",
       " \"['announcing', 'apache', 'flink', '1', '0', '0']\",\n",
       " \"['train', 'image', 'classifier', 'inception', 'tensorflow']\",\n",
       " \"['neural', 'doodles', 'workflows', 'next', 'generation', 'artists']\",\n",
       " \"['question', 'want', 'say', 'working', 'data']\",\n",
       " \"['graph', 'databases', '101']\",\n",
       " \"['statisticians', 'agree', '???', 'time', 'stop', 'misusing', 'p', 'value']\",\n",
       " \"['xgboost', 'scalable', 'tree', 'boosting', 'system', 'article']\",\n",
       " \"['top', '50', 'data', 'science', 'thought', 'leaders', 'twitter']\",\n",
       " \"['international', 'women', 'day', '#', 'pledgeforparity', 'means', 'us']\",\n",
       " \"['unsupervised', 'learning', 'even', 'less', 'supervision', 'using', 'bayesian', 'optimization']\",\n",
       " \"['announcing', 'r', 'tools', 'visual', 'studio']\",\n",
       " \"['genomic', 'ranges', 'introduction', 'working', 'genomic', 'data']\",\n",
       " \"['deriving', 'better', 'insights', 'time', 'series', 'data', 'cycle', 'plots']\",\n",
       " \"['drivendata', 'competition', 'model', 'visualize', 'fog', 'patterns', 'morocco']\",\n",
       " \"['introducing', 'graphframes']\",\n",
       " \"['ask', 'dt', 'hiring', 'march', '2016']\",\n",
       " \"['deep', 'learning', 'nine', 'lectures', 'coll', '??', 'ge', 'de', 'france', 'yan', 'lecun']\",\n",
       " \"['tensorflow', 'poets']\",\n",
       " \"['work', 'large', 'json', 'datasets', 'using', 'python', 'pandas']\",\n",
       " \"['sql', 'data', 'analysis']\",\n",
       " \"['stream', 'processing', 'messaging', 'systems', 'iot', 'age']\",\n",
       " \"['optimizing', 'facebook', 'campaigns', 'r']\",\n",
       " \"['trump', 'tweets', 'globe', 'aka', 'fun', 'd3', 'socket', 'io', 'twitter', 'api']\",\n",
       " \"['pandas', 'users', 'excited', 'apache', 'arrow']\",\n",
       " \"['histogram', 'intersection', 'change', 'detection']\",\n",
       " \"['simpler', 'way', 'merge', 'data', 'streams']\",\n",
       " \"['distributed', 'tensorflow', 'open', 'sourced']\",\n",
       " \"['d3', 'js', 'screencasts', '1', '3', 'free']\",\n",
       " \"['regression', 'classification', 'examples', 'r']\",\n",
       " \"['free', 'online', 'course', 'statistical', 'shape', 'modelling']\",\n",
       " \"['worry', 'deep', 'learning', 'deepen', 'understanding', 'causality', 'instead']\",\n",
       " \"['skizze', 'high', 'throughput', 'probabilistic', 'data', 'structure', 'service', 'storage']\",\n",
       " \"['work', 'private', 'repositories', 'updates', 'flyelephant', 'platform']\",\n",
       " \"['import', 'xml', 'almost', 'anywhere']\",\n",
       " \"['optimizing', 'notification', 'timing', 'one', 'signal']\",\n",
       " \"['survival', 'analysis', 'cricket', 'player', 'careers']\",\n",
       " \"['generate', 'image', 'analogies', 'using', 'neural', 'matching', 'blending']\",\n",
       " \"['analyzing', '1', '8m', 'tweets', 'super', 'bowl', '50', 'twython', 'twitter', 'api', 'aylien']\",\n",
       " \"['newly', 'released', 'sklearn', 'compatible', 'library', 'categorical', 'encoders']\",\n",
       " \"['watch', 'tiny', 'neural', 'nets', 'learn']\",\n",
       " \"['four', 'pitfalls', 'hill', 'climbing', 'animated', 'look']\",\n",
       " \"['decision', 'forests', 'convolutional', 'networks', 'models']\",\n",
       " \"['math', 'genius', 'hacked', 'okcupid', 'find', 'true', 'love']\",\n",
       " \"['developers', 'pylearn2']\",\n",
       " \"['density', 'estimation', 'dirichlet', 'process', 'mixtures', 'using', 'pymc3']\",\n",
       " \"['using', 'survival', 'analysis', 'git', 'pandas', 'estimate', 'code', 'quality']\",\n",
       " \"['analysis', 'flint', 'michigan', 'water', 'crisis', 'part', '1', 'initial', 'corrosivity']\",\n",
       " \"['analysis', 'republican', 'twitter', 'follower', 'interests']\",\n",
       " \"['introduction', 'ml', 'talk']\",\n",
       " \"['glove', 'vs', 'word2vec', 'revisited']\",\n",
       " \"['undergrad', 'data', 'analysis', 'science', 'internships', 'sf', 'bay']\",\n",
       " \"['role', 'statistical', 'significance', 'growth', 'hacking']\",\n",
       " \"['data', 'science', 'course', '@', 'harvard']\",\n",
       " \"['principal', 'component', 'projection', 'without', 'principal', 'component', 'analysis']\",\n",
       " \"['machine', 'learning', 'depth', 'non', 'technical', 'guide', 'part', '3']\",\n",
       " \"['stochastic', 'dummy', 'boosting']\",\n",
       " \"['interactive', 'map', 'hong', 'kong', 'lense', 'instagram']\",\n",
       " \"['data', 'science', 'monsanto']\",\n",
       " \"['data', 'science', 'instacart']\",\n",
       " \"['building', 'streaming', 'search', 'platform']\",\n",
       " \"['sneak', 'peak', 'cloud', '2', 'minute', 'intro', 'beginners']\",\n",
       " \"['win', 'vector', 'video', 'courses', 'price', 'status', 'changes']\",\n",
       " \"['50', '+', 'data', 'science', 'machine', 'learning', 'cheat', 'sheets']\",\n",
       " \"['one', 'reason', 'scared', 'deep', 'learning']\",\n",
       " \"['visual', 'logic', 'authoring', 'vs', 'code']\",\n",
       " \"['data', 'science', 'python', 'online', 'training', 'hands', 'experience']\",\n",
       " \"['viewing', 'us', 'presidential', 'primary', 'lens', 'twitter']\",\n",
       " \"['caffe', 'spark', 'open', 'sourced']\",\n",
       " \"['ethical', 'data', 'scientist']\",\n",
       " \"['answers', 'frequently', 'asked', 'questions', 'machine', 'learning']\",\n",
       " \"['intro', 'b', 'testing', 'p', 'values']\",\n",
       " \"['visualizing', 'state', 'level', 'data', 'r', 'statebins']\",\n",
       " \"['probabilistic', 'graphical', 'models', 'slides', '&', 'video', 'lectures', 'eric', 'xing', 'cmu']\",\n",
       " \"['sense2vec', 'spacy', 'gensim']\",\n",
       " \"['code', 'understand', 'deepmind', 'neural', 'stack', 'machine', 'python']\",\n",
       " \"['make', 'polished', 'jupyter', 'presentations', 'optional', 'code', 'visibility']\",\n",
       " \"['become', 'bayesian', 'eight', 'easy', 'steps']\",\n",
       " \"['optimizing', '.*:', 'details', 'vectorization', 'metaprogramming', 'julia']\",\n",
       " \"['ibm', 'certified', 'apache', 'spark', 'online', 'training']\",\n",
       " \"['geographic', 'data', 'science', 'course']\",\n",
       " \"['daily', 'mail', 'stole', 'visualization', 'twice']\",\n",
       " \"['ensemble', 'methods', 'improved', 'machine', 'learning', 'results']\",\n",
       " \"['apache', 'spark', 'unsupervised', 'learning', 'security']\",\n",
       " \"['machinejs', 'automated', 'machine', 'learning', 'give', 'data', 'file']\",\n",
       " \"['kafka', 'producer', 'latency', 'large', 'topic', 'counts']\",\n",
       " \"['nsa', '???', 'skynet', 'program', 'may', 'killing', 'thousands', 'innocent', 'people']\",\n",
       " \"['overoptimizing', 'story', 'kaggle']\",\n",
       " \"['big', 'dimensions']\",\n",
       " \"['automate', 'oscars', 'pool', 'r']\",\n",
       " \"['signal', 'processing', 'ligo', 'gw150914', 'data']\",\n",
       " \"['overview', 'dezyre', 'coursera', 'data', 'science', 'course']\",\n",
       " \"['upcoming', 'datathon', 'nyc']\",\n",
       " \"['summarizing', 'data', 'sql']\",\n",
       " \"['b', 'testing', 'scammers']\",\n",
       " \"['highly', 'interpretable', 'classifiers', 'scikit', 'learn', 'using', 'bayesian', 'decision', 'rules']\",\n",
       " \"['auto', 'scaling', 'scikit', 'learn', 'spark']\",\n",
       " \"['f', '***', 'park']\",\n",
       " \"['machine', 'learning', 'depth', 'non', 'technical', 'guide', 'part', '2']\",\n",
       " \"['webhose', 'io', 'offers', 'historical', 'data', 'archive']\",\n",
       " \"['meetup', 'introduction', 'machine', 'learning', 'algorithms', 'data', 'science']\",\n",
       " \"['exploring', 'limits', 'language', 'modeling']\",\n",
       " \"['text', 'mining', 'south', 'park']\",\n",
       " \"['finding', 'k', 'k', 'means', 'parametric', 'bootstrap']\",\n",
       " \"['billion', 'nyc', 'taxi', 'uber', 'rides', 'aws', 'redshift']\",\n",
       " \"['getting', 'started', 'statistics', 'data', 'science']\",\n",
       " \"['rodeo', '1', '3', 'tab', 'completion', 'docstrings']\",\n",
       " \"['teaching', 'd3', 'js', 'links']\",\n",
       " \"['parallel', 'scikit', 'learn', 'yarn']\",\n",
       " \"['meetup', 'free', 'live', 'webinar', 'prescriptive', 'analytics', 'fun', 'profit']\",\n",
       " \"['access', 'vk', 'com', 'vkontakte', 'api', 'via', 'r']\",\n",
       " \"['deep', 'learning', 'tutorial', 'lecun', 'bengio']\",\n",
       " \"['machine', 'learning', 'meets', 'economics']\",\n",
       " \"['culll', 'data', 'science', 'culled', 'best']\",\n",
       " \"['topic', 'modelling', 'parliamentary', 'debate', 'records']\",\n",
       " \"['ask', 'dt', 'hiring', 'february', '2016']\",\n",
       " \"['day', 'life', 'data', 'scientist', 'rutgers', 'online']\",\n",
       " \"['gpu', 'computing', 'data', 'science']\",\n",
       " \"['big', 'data', 'landscape', 'database', '675', '+', 'big', 'data', 'players']\",\n",
       " \"['deep', 'learning', 'udacity', 'course']\",\n",
       " \"['kaggle', 'learned', '2', 'million', 'machine', 'learning', 'models']\",\n",
       " \"['making', 'causal', 'impact', 'analysis', 'easy']\",\n",
       " \"['recommendation', 'system', 'blogs', 'content', 'based', 'similarity', 'part', '2']\",\n",
       " \"['turing', 'art', 'test']\",\n",
       " \"['happiness', 'paradox', 'friends', 'happier']\",\n",
       " \"['deep', 'learning', 'spark', 'tensorflow']\",\n",
       " \"['statistical', 'computing']\",\n",
       " \"['alphago', 'using', 'machine', 'learning', 'master', 'ancient', 'game', 'go']\",\n",
       " \"['census', 'analyzer', 'preview', 'technology', 'web', 'based', 'tool', 'data', 'analysis']\",\n",
       " \"['introduction', 'java', 'web', 'scraping']\",\n",
       " \"['market', 'basket', 'analysis', 'using', 'r']\",\n",
       " \"['marvin', 'minsky', 'pioneer', 'artificial', 'intelligence', 'dies', '88']\",\n",
       " \"['open', 'source', 'deep', 'learning', 'server']\",\n",
       " \"['spark', 'ts', 'new', 'library', 'analyzing', 'time', 'series', 'data', 'apache', 'spark']\",\n",
       " \"['exploration', 'convnet', 'filters', 'keras']\",\n",
       " \"['applied', 'spatial', 'data', 'science', 'r']\",\n",
       " \"['secrets', 'building', 'data', 'driven', 'organization']\",\n",
       " \"['philly', 'tweets']\",\n",
       " \"['neglected', 'data', 'science', 'optimization', 'topic', 'set', 'diversity']\",\n",
       " \"['machine', 'learning', 'depth', 'non', 'technical', 'guide', 'part', '2']\",\n",
       " \"['statistical', 'dependency', 'parsing', 'using', 'svm', 'python', '@', 'rj_here']\",\n",
       " \"['5', 'reasons', 'kaggle', 'projects', 'help', 'data', 'science', 'resume']\",\n",
       " \"['deep', 'learning', 'glossary']\",\n",
       " \"['teaching', 'semester', 'd3', 'js']\",\n",
       " \"['finding', 'nearest', 'neighbors', 'sql']\",\n",
       " \"['free', 'data', 'science', 'curriculum']\",\n",
       " \"['deep', 'learning', 'easy', 'learn', 'something', 'harder']\",\n",
       " \"['flyelephant', 'tool', 'calculations', 'c', '++,', 'r', 'python', 'octave']\",\n",
       " \"['yahoo', 'releases', 'largest', 'ever', 'machine', 'learning', 'dataset', 'researchers']\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let us get the frequency count\n",
    "frequency_words = {}\n",
    "for data in tokens_list:\n",
    "    data = data.replace(\"[\",\"\")\n",
    "    data = data.replace(\"]\",\"\")\n",
    "    data = data.replace(\"'\",\"\")\n",
    "    data_list = data.split(',')\n",
    "    for token in data_list:\n",
    "        if token not in stop:\n",
    "            if token in frequency_words:\n",
    "                count = frequency_words[token]\n",
    "                count = count + 1\n",
    "                frequency_words[token] = count\n",
    "            else:\n",
    "                frequency_words[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 1,\n",
       " ' #': 1,\n",
       " ' &': 1,\n",
       " ' ***': 1,\n",
       " ' +': 2,\n",
       " ' ++': 1,\n",
       " ' .*:': 1,\n",
       " ' 0': 2,\n",
       " ' 1': 5,\n",
       " ' 101': 1,\n",
       " ' 16': 1,\n",
       " ' 2': 5,\n",
       " ' 2016': 2,\n",
       " ' 3': 3,\n",
       " ' 4': 1,\n",
       " ' 50': 2,\n",
       " ' 675': 1,\n",
       " ' 88': 1,\n",
       " ' 8m': 1,\n",
       " ' ??': 1,\n",
       " ' ???': 3,\n",
       " ' @': 2,\n",
       " ' affect': 1,\n",
       " ' age': 1,\n",
       " ' agree': 1,\n",
       " ' aka': 1,\n",
       " ' algorithms': 1,\n",
       " ' almost': 1,\n",
       " ' amazon': 1,\n",
       " ' analogies': 1,\n",
       " ' analysis': 9,\n",
       " ' analytical': 1,\n",
       " ' analytics': 1,\n",
       " ' analyzer': 1,\n",
       " ' analyzing': 1,\n",
       " ' ancient': 1,\n",
       " ' animated': 1,\n",
       " ' anywhere': 1,\n",
       " ' apache': 5,\n",
       " ' api': 4,\n",
       " ' app': 1,\n",
       " ' apple': 1,\n",
       " ' archive': 1,\n",
       " ' arrow': 1,\n",
       " ' art': 1,\n",
       " ' article': 1,\n",
       " ' artificial': 2,\n",
       " ' artists': 1,\n",
       " ' asked': 1,\n",
       " ' austin': 1,\n",
       " ' authoring': 1,\n",
       " ' automated': 1,\n",
       " ' aws': 1,\n",
       " ' aylien': 1,\n",
       " ' b': 1,\n",
       " ' background': 1,\n",
       " ' based': 2,\n",
       " ' basket': 1,\n",
       " ' bay': 1,\n",
       " ' bayesian': 4,\n",
       " ' beginners': 1,\n",
       " ' bengio': 1,\n",
       " ' best': 1,\n",
       " ' better': 2,\n",
       " ' big': 2,\n",
       " ' biggest': 1,\n",
       " ' blending': 1,\n",
       " ' blogs': 1,\n",
       " ' boosting': 2,\n",
       " ' bootstrap': 1,\n",
       " ' bowl': 1,\n",
       " ' building': 1,\n",
       " ' c': 1,\n",
       " ' calculations': 1,\n",
       " ' campaigns': 1,\n",
       " ' careers': 1,\n",
       " ' cartoon': 1,\n",
       " ' categorical': 1,\n",
       " ' causal': 1,\n",
       " ' causality': 1,\n",
       " ' certified': 1,\n",
       " ' change': 1,\n",
       " ' changed': 1,\n",
       " ' changes': 1,\n",
       " ' channel': 1,\n",
       " ' characters': 1,\n",
       " ' charts': 1,\n",
       " ' cheat': 1,\n",
       " ' choice': 1,\n",
       " ' choices': 1,\n",
       " ' classification': 2,\n",
       " ' classifier': 1,\n",
       " ' classifiers': 1,\n",
       " ' click': 1,\n",
       " ' climbing': 1,\n",
       " ' cloud': 1,\n",
       " ' cmu': 1,\n",
       " ' code': 3,\n",
       " ' coll': 1,\n",
       " ' com': 1,\n",
       " ' compatible': 1,\n",
       " ' competition': 1,\n",
       " ' completion': 1,\n",
       " ' component': 2,\n",
       " ' computing': 3,\n",
       " ' condition': 1,\n",
       " ' content': 1,\n",
       " ' convnet': 1,\n",
       " ' convolutional': 1,\n",
       " ' corrosivity': 1,\n",
       " ' counts': 1,\n",
       " ' course': 5,\n",
       " ' coursera': 1,\n",
       " ' courses': 1,\n",
       " ' cricket': 1,\n",
       " ' crisis': 1,\n",
       " ' culled': 1,\n",
       " ' curriculum': 1,\n",
       " ' cycle': 1,\n",
       " ' d3': 3,\n",
       " ' data': 34,\n",
       " ' database': 1,\n",
       " ' databases': 1,\n",
       " ' dataflow': 1,\n",
       " ' dataset': 1,\n",
       " ' datasets': 1,\n",
       " ' datathon': 1,\n",
       " ' day': 1,\n",
       " ' de': 1,\n",
       " ' debate': 1,\n",
       " ' decision': 1,\n",
       " ' deep': 3,\n",
       " ' deepen': 1,\n",
       " ' deepmind': 1,\n",
       " ' demo': 1,\n",
       " ' demystified': 1,\n",
       " ' dependency': 1,\n",
       " ' depth': 4,\n",
       " ' details': 2,\n",
       " ' detecting': 1,\n",
       " ' detection': 1,\n",
       " ' dezyre': 1,\n",
       " ' dies': 1,\n",
       " ' dimensions': 1,\n",
       " ' dirichlet': 1,\n",
       " ' distributed': 1,\n",
       " ' diversity': 1,\n",
       " ' docstrings': 1,\n",
       " ' doodles': 1,\n",
       " ' driven': 1,\n",
       " ' dt': 2,\n",
       " ' dummy': 1,\n",
       " ' ea': 1,\n",
       " ' easy': 3,\n",
       " ' economics': 1,\n",
       " ' eight': 1,\n",
       " ' emr': 1,\n",
       " ' encoders': 1,\n",
       " ' engineers': 1,\n",
       " ' eric': 1,\n",
       " ' estimate': 1,\n",
       " ' estimation': 2,\n",
       " ' evaluation': 1,\n",
       " ' even': 1,\n",
       " ' ever': 1,\n",
       " ' examples': 1,\n",
       " ' excited': 1,\n",
       " ' experience': 1,\n",
       " ' experiments': 1,\n",
       " ' facebook': 1,\n",
       " ' fast': 1,\n",
       " ' fatigue': 1,\n",
       " ' february': 1,\n",
       " ' fifa': 1,\n",
       " ' file': 1,\n",
       " ' filters': 1,\n",
       " ' find': 1,\n",
       " ' flink': 2,\n",
       " ' flint': 1,\n",
       " ' flow': 1,\n",
       " ' flyelephant': 1,\n",
       " ' fog': 1,\n",
       " ' follower': 1,\n",
       " ' forests': 1,\n",
       " ' france': 1,\n",
       " ' free': 2,\n",
       " ' frequently': 1,\n",
       " ' friends': 1,\n",
       " ' fun': 2,\n",
       " ' g': 1,\n",
       " ' game': 1,\n",
       " ' ge': 1,\n",
       " ' generation': 1,\n",
       " ' genius': 1,\n",
       " ' genomic': 1,\n",
       " ' gensim': 1,\n",
       " ' git': 2,\n",
       " ' gitnoc': 1,\n",
       " ' give': 1,\n",
       " ' globe': 1,\n",
       " ' glossary': 1,\n",
       " ' go': 1,\n",
       " ' golden': 1,\n",
       " ' graphframes': 2,\n",
       " ' graphical': 1,\n",
       " ' growth': 1,\n",
       " ' guide': 4,\n",
       " ' gw150914': 1,\n",
       " ' hacked': 1,\n",
       " ' hacking': 1,\n",
       " ' hands': 1,\n",
       " ' happier': 1,\n",
       " ' harder': 1,\n",
       " ' harvard': 1,\n",
       " ' heart': 1,\n",
       " ' help': 1,\n",
       " ' high': 1,\n",
       " ' hill': 1,\n",
       " ' hiring': 2,\n",
       " ' historical': 1,\n",
       " ' hong': 1,\n",
       " ' image': 2,\n",
       " ' impact': 1,\n",
       " ' improved': 1,\n",
       " ' inception': 1,\n",
       " ' initial': 1,\n",
       " ' innocent': 1,\n",
       " ' insights': 1,\n",
       " ' instacart': 1,\n",
       " ' instagram': 1,\n",
       " ' instead': 1,\n",
       " ' intelligence': 2,\n",
       " ' interactive': 1,\n",
       " ' interests': 1,\n",
       " ' interface': 1,\n",
       " ' internships': 1,\n",
       " ' interpretable': 1,\n",
       " ' intersection': 1,\n",
       " ' intro': 2,\n",
       " ' introduction': 2,\n",
       " ' invaders': 1,\n",
       " ' invite': 1,\n",
       " ' io': 2,\n",
       " ' iot': 1,\n",
       " ' java': 1,\n",
       " ' javascript': 1,\n",
       " ' js': 3,\n",
       " ' json': 1,\n",
       " ' julia': 1,\n",
       " ' jupyter': 1,\n",
       " ' k': 2,\n",
       " ' kaggle': 2,\n",
       " ' keras': 1,\n",
       " ' killing': 1,\n",
       " ' know': 1,\n",
       " ' kong': 1,\n",
       " ' landscape': 1,\n",
       " ' language': 3,\n",
       " ' large': 2,\n",
       " ' largest': 1,\n",
       " ' latency': 1,\n",
       " ' leaders': 1,\n",
       " ' learn': 6,\n",
       " ' learned': 1,\n",
       " ' learning': 28,\n",
       " ' lectures': 2,\n",
       " ' lecun': 2,\n",
       " ' lens': 1,\n",
       " ' lense': 1,\n",
       " ' less': 1,\n",
       " ' level': 1,\n",
       " ' library': 2,\n",
       " ' life': 1,\n",
       " ' ligo': 1,\n",
       " ' limits': 1,\n",
       " ' links': 1,\n",
       " ' live': 1,\n",
       " ' logic': 1,\n",
       " ' look': 1,\n",
       " ' losers': 1,\n",
       " ' love': 1,\n",
       " ' machine': 11,\n",
       " ' mail': 1,\n",
       " ' manifold': 1,\n",
       " ' map': 1,\n",
       " ' march': 1,\n",
       " ' master': 1,\n",
       " ' matching': 1,\n",
       " ' math': 1,\n",
       " ' may': 1,\n",
       " ' means': 2,\n",
       " ' meets': 1,\n",
       " ' merge': 1,\n",
       " ' messaging': 1,\n",
       " ' metaprogramming': 1,\n",
       " ' methods': 1,\n",
       " ' metrics': 1,\n",
       " ' michigan': 1,\n",
       " ' million': 1,\n",
       " ' millions': 1,\n",
       " ' mining': 2,\n",
       " ' minsky': 1,\n",
       " ' minute': 1,\n",
       " ' misusing': 1,\n",
       " ' mixtures': 1,\n",
       " ' ml': 1,\n",
       " ' model': 1,\n",
       " ' modeling': 1,\n",
       " ' modelling': 2,\n",
       " ' models': 3,\n",
       " ' moneyball': 1,\n",
       " ' monsanto': 1,\n",
       " ' morocco': 1,\n",
       " ' natural': 1,\n",
       " ' nba': 1,\n",
       " ' nearest': 1,\n",
       " ' neighbors': 1,\n",
       " ' nets': 1,\n",
       " ' network': 1,\n",
       " ' networks': 2,\n",
       " ' neural': 3,\n",
       " ' new': 1,\n",
       " ' next': 1,\n",
       " ' nine': 1,\n",
       " ' non': 4,\n",
       " ' notification': 1,\n",
       " ' numerical': 1,\n",
       " ' nyc': 2,\n",
       " ' octave': 1,\n",
       " ' offers': 1,\n",
       " ' okcupid': 1,\n",
       " ' one': 1,\n",
       " ' online': 4,\n",
       " ' open': 3,\n",
       " ' optimization': 2,\n",
       " ' optional': 1,\n",
       " ' organization': 1,\n",
       " ' oscars': 1,\n",
       " ' owners': 1,\n",
       " ' p': 2,\n",
       " ' pandas': 3,\n",
       " ' paradox': 1,\n",
       " ' parametric': 1,\n",
       " ' park': 2,\n",
       " ' parliamentary': 1,\n",
       " ' parsing': 1,\n",
       " ' part': 6,\n",
       " ' passing': 1,\n",
       " ' patterns': 1,\n",
       " ' peak': 1,\n",
       " ' people': 1,\n",
       " ' phys': 1,\n",
       " ' pioneer': 1,\n",
       " ' pitfalls': 1,\n",
       " ' platform': 2,\n",
       " ' player': 1,\n",
       " ' players': 1,\n",
       " ' pledgeforparity': 1,\n",
       " ' plots': 1,\n",
       " ' poets': 1,\n",
       " ' points': 1,\n",
       " ' polished': 1,\n",
       " ' pool': 1,\n",
       " ' pop': 1,\n",
       " ' portable': 1,\n",
       " ' prescriptive': 1,\n",
       " ' presentations': 1,\n",
       " ' presidential': 1,\n",
       " ' presto': 1,\n",
       " ' preview': 1,\n",
       " ' price': 1,\n",
       " ' primary': 1,\n",
       " ' principal': 1,\n",
       " ' private': 1,\n",
       " ' probabilistic': 1,\n",
       " ' process': 1,\n",
       " ' processing': 3,\n",
       " ' producer': 1,\n",
       " ' profit': 1,\n",
       " ' program': 1,\n",
       " ' projection': 1,\n",
       " ' projects': 1,\n",
       " ' pylearn2': 1,\n",
       " ' pymc3': 1,\n",
       " ' python': 7,\n",
       " ' q': 1,\n",
       " ' quality': 1,\n",
       " ' questions': 1,\n",
       " ' r': 11,\n",
       " ' ranges': 1,\n",
       " ' rate': 1,\n",
       " ' reason': 1,\n",
       " ' reasons': 1,\n",
       " ' records': 1,\n",
       " ' redshift': 1,\n",
       " ' released': 1,\n",
       " ' releases': 1,\n",
       " ' repositories': 1,\n",
       " ' republican': 1,\n",
       " ' researchers': 1,\n",
       " ' rest': 1,\n",
       " ' results': 2,\n",
       " ' resume': 1,\n",
       " ' revisited': 1,\n",
       " ' rides': 2,\n",
       " ' rj_here': 1,\n",
       " ' roots': 1,\n",
       " ' rules': 1,\n",
       " ' run': 1,\n",
       " ' running': 2,\n",
       " ' rutgers': 1,\n",
       " ' say': 1,\n",
       " ' scalable': 1,\n",
       " ' scaling': 1,\n",
       " ' scammers': 1,\n",
       " ' scared': 1,\n",
       " ' science': 21,\n",
       " ' scientist': 2,\n",
       " ' scikit': 4,\n",
       " ' scraping': 1,\n",
       " ' screencasts': 1,\n",
       " ' search': 1,\n",
       " ' security': 1,\n",
       " ' semester': 1,\n",
       " ' series': 2,\n",
       " ' server': 1,\n",
       " ' service': 1,\n",
       " ' set': 1,\n",
       " ' sf': 1,\n",
       " ' shape': 1,\n",
       " ' sheets': 1,\n",
       " ' shiny': 1,\n",
       " ' shot': 1,\n",
       " ' signal': 1,\n",
       " ' significance': 1,\n",
       " ' similarity': 1,\n",
       " ' simplified': 1,\n",
       " ' sklearn': 1,\n",
       " ' skynet': 1,\n",
       " ' slack': 1,\n",
       " ' slides': 1,\n",
       " ' socket': 1,\n",
       " ' something': 1,\n",
       " ' source': 2,\n",
       " ' sourced': 2,\n",
       " ' south': 1,\n",
       " ' space': 2,\n",
       " ' spacy': 1,\n",
       " ' spark': 9,\n",
       " ' spatial': 1,\n",
       " ' sql': 3,\n",
       " ' stack': 1,\n",
       " ' started': 1,\n",
       " ' state': 2,\n",
       " ' statebins': 1,\n",
       " ' statistical': 2,\n",
       " ' statistics': 2,\n",
       " ' status': 1,\n",
       " ' steps': 1,\n",
       " ' stole': 1,\n",
       " ' stop': 1,\n",
       " ' storage': 1,\n",
       " ' story': 1,\n",
       " ' streaming': 1,\n",
       " ' streams': 1,\n",
       " ' structure': 1,\n",
       " ' studio': 1,\n",
       " ' super': 1,\n",
       " ' supervision': 1,\n",
       " ' survival': 1,\n",
       " ' svm': 1,\n",
       " ' system': 2,\n",
       " ' systems': 1,\n",
       " ' tab': 1,\n",
       " ' talk': 1,\n",
       " ' tau': 1,\n",
       " ' taxi': 2,\n",
       " ' technical': 4,\n",
       " ' technologies': 1,\n",
       " ' technology': 1,\n",
       " ' tensorflow': 5,\n",
       " ' test': 1,\n",
       " ' testing': 2,\n",
       " ' text': 1,\n",
       " ' thought': 1,\n",
       " ' thousands': 1,\n",
       " ' throughput': 1,\n",
       " ' time': 3,\n",
       " ' times': 1,\n",
       " ' timeseries': 1,\n",
       " ' timing': 1,\n",
       " ' tiny': 1,\n",
       " ' tool': 2,\n",
       " ' tools': 2,\n",
       " ' topic': 2,\n",
       " ' train': 1,\n",
       " ' training': 2,\n",
       " ' transparent': 1,\n",
       " ' tree': 1,\n",
       " ' true': 1,\n",
       " ' ts': 1,\n",
       " ' tutorial': 1,\n",
       " ' tweets': 3,\n",
       " ' twice': 1,\n",
       " ' twitter': 5,\n",
       " ' twython': 1,\n",
       " ' tx': 1,\n",
       " ' uber': 1,\n",
       " ' udacity': 1,\n",
       " ' understand': 1,\n",
       " ' understanding': 1,\n",
       " ' undiagnosed': 1,\n",
       " ' unsupervised': 1,\n",
       " ' updates': 1,\n",
       " ' us': 2,\n",
       " ' use': 1,\n",
       " ' users': 1,\n",
       " ' using': 9,\n",
       " ' value': 1,\n",
       " ' values': 1,\n",
       " ' variations': 1,\n",
       " ' vector': 1,\n",
       " ' vectorization': 1,\n",
       " ' via': 1,\n",
       " ' video': 2,\n",
       " ' visibility': 1,\n",
       " ' visual': 1,\n",
       " ' visualization': 1,\n",
       " ' visualize': 1,\n",
       " ' vk': 1,\n",
       " ' vkontakte': 1,\n",
       " ' vs': 2,\n",
       " ' wait': 1,\n",
       " ' want': 1,\n",
       " ' warriors': 1,\n",
       " ' watch': 1,\n",
       " ' water': 1,\n",
       " ' way': 1,\n",
       " ' web': 2,\n",
       " ' webinar': 1,\n",
       " ' winners': 1,\n",
       " ' without': 1,\n",
       " ' women': 1,\n",
       " ' word2vec': 1,\n",
       " ' work': 1,\n",
       " ' workflows': 1,\n",
       " ' working': 2,\n",
       " ' xgboost': 1,\n",
       " ' xing': 1,\n",
       " ' xml': 1,\n",
       " ' yan': 1,\n",
       " ' yarn': 1,\n",
       " ' years': 1,\n",
       " '10': 1,\n",
       " '5': 1,\n",
       " '50': 1,\n",
       " '7': 1,\n",
       " 'access': 1,\n",
       " 'alphago': 1,\n",
       " 'analysis': 2,\n",
       " 'analyzing': 2,\n",
       " 'announcing': 2,\n",
       " 'answers': 1,\n",
       " 'apache': 1,\n",
       " 'applied': 1,\n",
       " 'ask': 2,\n",
       " 'auto': 1,\n",
       " 'automate': 1,\n",
       " 'b': 1,\n",
       " 'ballr': 1,\n",
       " 'bayesian': 1,\n",
       " 'become': 1,\n",
       " 'big': 2,\n",
       " 'billion': 2,\n",
       " 'building': 1,\n",
       " 'caffe': 1,\n",
       " 'census': 1,\n",
       " 'code': 1,\n",
       " 'computing': 1,\n",
       " 'conversion': 1,\n",
       " 'culll': 1,\n",
       " 'd3': 1,\n",
       " 'daily': 1,\n",
       " 'data': 8,\n",
       " 'day': 1,\n",
       " 'decision': 1,\n",
       " 'deep': 8,\n",
       " 'density': 1,\n",
       " 'deriving': 1,\n",
       " 'descriptive': 1,\n",
       " 'developers': 1,\n",
       " 'distributed': 1,\n",
       " 'drivendata': 1,\n",
       " 'ensemble': 1,\n",
       " 'ethical': 1,\n",
       " 'exploration': 1,\n",
       " 'exploring': 1,\n",
       " 'f': 1,\n",
       " 'file': 1,\n",
       " 'finding': 2,\n",
       " 'flyelephant': 1,\n",
       " 'four': 1,\n",
       " 'free': 2,\n",
       " 'generate': 1,\n",
       " 'genomic': 1,\n",
       " 'geographic': 1,\n",
       " 'getting': 1,\n",
       " 'glove': 1,\n",
       " 'gpu': 1,\n",
       " 'graph': 1,\n",
       " 'happiness': 1,\n",
       " 'highly': 1,\n",
       " 'histogram': 1,\n",
       " 'ibm': 1,\n",
       " 'import': 1,\n",
       " 'intellexer': 1,\n",
       " 'interactive': 1,\n",
       " 'international': 1,\n",
       " 'intro': 1,\n",
       " 'introducing': 1,\n",
       " 'introduction': 3,\n",
       " 'julia': 1,\n",
       " 'kafka': 1,\n",
       " 'kaggle': 1,\n",
       " 'learn': 1,\n",
       " 'machine': 5,\n",
       " 'machinejs': 1,\n",
       " 'machines': 1,\n",
       " 'make': 2,\n",
       " 'making': 2,\n",
       " 'market': 1,\n",
       " 'marvin': 1,\n",
       " 'math': 1,\n",
       " 'meetup': 2,\n",
       " 'megaman': 1,\n",
       " 'minecraft': 1,\n",
       " 'neglected': 1,\n",
       " 'neural': 2,\n",
       " 'newly': 1,\n",
       " 'nsa': 1,\n",
       " 'one': 1,\n",
       " 'open': 1,\n",
       " 'optimizing': 3,\n",
       " 'overoptimizing': 1,\n",
       " 'overview': 1,\n",
       " 'pandas': 1,\n",
       " 'parallel': 1,\n",
       " 'personality': 1,\n",
       " 'philly': 1,\n",
       " 'playing': 1,\n",
       " 'principal': 1,\n",
       " 'probabilistic': 1,\n",
       " 'question': 1,\n",
       " 'recommendation': 1,\n",
       " 'regression': 1,\n",
       " 'rodeo': 1,\n",
       " 'role': 1,\n",
       " 'scala': 1,\n",
       " 'secrets': 1,\n",
       " 'sense2vec': 1,\n",
       " 'shiny': 1,\n",
       " 'signal': 1,\n",
       " 'simpler': 1,\n",
       " 'skizze': 1,\n",
       " 'sneak': 1,\n",
       " 'spark': 1,\n",
       " 'sql': 1,\n",
       " 'statistical': 2,\n",
       " 'statisticians': 1,\n",
       " 'stochastic': 1,\n",
       " 'stream': 1,\n",
       " 'summarizing': 1,\n",
       " 'survival': 1,\n",
       " 'teaching': 2,\n",
       " 'tensorflow': 1,\n",
       " 'text': 1,\n",
       " 'top': 1,\n",
       " 'topic': 1,\n",
       " 'train': 1,\n",
       " 'trump': 1,\n",
       " 'turing': 1,\n",
       " 'undergrad': 1,\n",
       " 'unsupervised': 1,\n",
       " 'upcoming': 1,\n",
       " 'using': 1,\n",
       " 'viewing': 1,\n",
       " 'visual': 1,\n",
       " 'visualizing': 1,\n",
       " 'watch': 1,\n",
       " 'webhose': 1,\n",
       " 'win': 1,\n",
       " 'work': 2,\n",
       " 'worry': 1,\n",
       " 'xgboost': 1,\n",
       " 'xgboost4j': 1,\n",
       " 'yahoo': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency and Inverse Document Frequency\n",
    "\n",
    "tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.[1]:8 It is often used as a weighting factor in information retrieval and text mining. The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.\n",
    "\n",
    "Variations of the tf–idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query. tf–idf can be successfully used for stop-words filtering in various subject fields including text summarization and classification.\n",
    "\n",
    "Let us start with the **\"Term Frequency\" - TF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(data=list(frequency_words.items()),columns=['word','tf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bootstrap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caffe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pylearn2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  tf\n",
       "0   bootstrap   1\n",
       "1               1\n",
       "2       caffe   1\n",
       "3        data   8\n",
       "4    pylearn2   1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.sort_values(ascending=False, by = \"tf\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>data</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>learning</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>science</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>r</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>machine</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  tf\n",
       "441       data  34\n",
       "507   learning  28\n",
       "466    science  21\n",
       "116          r  11\n",
       "358    machine  11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get in how many documents (each title) does the word occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_documents_count(row):\n",
    "    document_counter = 0\n",
    "    word = row['word']\n",
    "    for document in df.tokens:\n",
    "        document = document.replace(\"'\",'')\n",
    "        document = document.replace(\"[\",'')\n",
    "        document = document.replace(\"]\",'')\n",
    "        if word in document:\n",
    "            document_counter = document_counter + 1\n",
    "        print(document)\n",
    "        print(document_counter)\n",
    "        break\n",
    "    return document_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "1\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n",
      "10, years, open, source, machine, learning\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_tfidf['document_count'] = df_tfidf.apply(get_documents_count,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "      <th>document_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>data</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>learning</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>science</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>r</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>machine</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  tf  document_count\n",
       "441       data  34              37\n",
       "507   learning  28              28\n",
       "466    science  21              21\n",
       "116          r  11              32\n",
       "358    machine  11              11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "      <th>document_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>certified</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>way</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>principal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>analytical</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>parsing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  tf  document_count\n",
       "252    certified   1               1\n",
       "253          way   1               1\n",
       "255    principal   1               1\n",
       "256   analytical   1               1\n",
       "695      parsing   1               1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we already have the count of all the documents\n",
    "total_docs = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** let us compute the tfidf ** \n",
    "\n",
    "**tfidf = tf . idf**\n",
    "\n",
    "**idf = log(total_docs/number of documents that contain the word)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_tfidf(row):\n",
    "    idf = math.log10(total_docs/row['document_count'])\n",
    "    return row['tf'] * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf['tfidf'] = df_tfidf.apply(compute_tfidf,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.sort(columns='tfidf',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.replace(to_replace=0.0,value=0.1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tfidf.set_index('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** now let us plot a word cloud to see the prominence of the word **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_tfidf = df_tfidf['tfidf'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcloud.generate_from_frequencies(word_tfidf.items())\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lda\n",
    "import numpy as np\n",
    "import lda.datasets\n",
    "import sklearn.feature_extraction.text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** we are using the pre built reuters data set **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = text.CountVectorizer(input='content', stop_words='english', min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df.title).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = df.title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lda.LDA(n_topics=5, n_iter=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.topic_word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_top_words = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_topic = model.doc_topic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(10):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"topic: {} , {}\".format(topic_most_pr,titles[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_features = []\n",
    "neg_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_full_dict(word):\n",
    "    return dict([(word, True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('postive_words.txt','r') as posFile:\n",
    "    lines = posFile.readlines()\n",
    "    for line in lines:\n",
    "        pos_features.append([make_full_dict(line.rstrip()),'pos'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('negative_words.txt','r',encoding='utf-8') as negFile:\n",
    "    lines = negFile.readlines()\n",
    "    for line in lines:\n",
    "        neg_features.append([make_full_dict(line.rstrip()),'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pos_features),len(neg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFeatures = pos_features + neg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(trainFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "referenceSets = collections.defaultdict(set)\n",
    "testSets = collections.defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_full_dict_sent(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_test = 'I hate data science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_words = re.findall(r\"[\\w']+|[.,!?;]\", 'I have a love and hate relationship with data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.append([make_full_dict_sent(title_words),''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, (features, label) in enumerate(test):\n",
    "    predicted = classifier.classify(features)\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc in df.title:\n",
    "    title_words = re.findall(r\"[\\w']+|[.,!?;]\", doc)\n",
    "    test = []\n",
    "    test.append([make_full_dict_sent(title_words),''])\n",
    "    for i, (features, label) in enumerate(test):\n",
    "        predicted = classifier.classify(features)\n",
    "        print(predicted,doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
